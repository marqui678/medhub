{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "import cPickle\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import re, string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.stop_words import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to import the same functions we used to vectorize, in order to repeat the process.\n",
    "\n",
    "def gettext(text):\n",
    "\n",
    "    \"\"\"\n",
    "    Parse text and remove JavaScript and references\n",
    "    \"\"\"\n",
    "    return text.replace(\"To use the sharing features on this page, please enable JavaScript.\", '').split(\"References\")[0]\n",
    "\n",
    "def tokenize_custom(text):\n",
    "    \"\"\"\n",
    "    Tokenize text and return a non-unique list of tokenized words\n",
    "    found in the text. Normalize to lowercase, strip punctuation,\n",
    "    remove stop words, drop words of length < 3.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    subs = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n' + ']')\n",
    "    processed_text = subs.sub(' ', text)\n",
    "    words = nltk.word_tokenize(processed_text)\n",
    "    words = [word for word in words if len(word) >=3 and word not in ENGLISH_STOP_WORDS]\n",
    "    return words\n",
    "\n",
    "def stemwords(words):\n",
    "    \"\"\"\n",
    "    Given a list of tokens/words, return a new list with each word\n",
    "    stemmed using a PorterStemmer.\n",
    "    \"\"\"\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    stemmed_list = [stemmer.stem_word(word) for word in words]\n",
    "    return stemmed_list\n",
    "\n",
    "def tokenizer_custom(text):\n",
    "    return stemwords(tokenize_custom(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have to write the user query to a text file because the transform function in tfidf expects RAW text documents. \n",
    "\n",
    "def write_query(query, file_dest = \"user_query.txt\"):\n",
    "    f = open(file_dest, 'w')\n",
    "    f.write(query)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vectorizer(filename):\n",
    "    fp = open(filename, 'rb')\n",
    "    clf = cPickle.load(fp)\n",
    "    fp.close()\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_disease_names(filename):\n",
    "    f = open(filename, 'r')\n",
    "    diseases = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    diseases = [disease.strip() for disease in diseases]\n",
    "    \n",
    "    return diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def disease_match(query_file = \"user_query.txt\",\n",
    "                  vectorizer_loc = \"diseases_data/vectorizer.pk\",\n",
    "                  disease_matrix_loc = \"diseases_data/disease_matrix.npz\",\n",
    "                 disease_names_loc = \"diseases_data/diseases.txt\"):\n",
    "    \n",
    "    diseases = load_disease_names(disease_names_loc)\n",
    "    tfidf = load_vectorizer(vectorizer_loc)\n",
    "    disease_matrix = load_sparse_csr(disease_matrix_loc)\n",
    "    \n",
    "    query_vector = tfidf.transform([query_file])\n",
    "    cosine_similarities = linear_kernel(query_vector, disease_matrix).flatten()\n",
    "    \n",
    "    # Get the top 5 matches to diseases\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-6:-1]\n",
    "    \n",
    "    return [(diseases[idx], cosine_similarities[idx]) for idx in related_docs_indices]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Joint swelling.txt', 0.80407964952685362),\n",
       " ('Joint pain.txt', 0.68293841285188439),\n",
       " ('Osteoarthritis.txt', 0.61580092291340971),\n",
       " ('Synovial fluid analysis.txt', 0.55550425565384876),\n",
       " ('Hypermobile joints.txt', 0.516365922606973)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query\n",
    "write_query(\"back pain joint swelling\")\n",
    "disease_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Scabies.txt', 0.22795127755014302),\n",
       " ('Rickettsialpox.txt', 0.16896717298726763),\n",
       " ('Chiggers.txt', 0.11327264032014427),\n",
       " ('Allergen.txt', 0.085123588268646841),\n",
       " ('Yellow fever.txt', 0.076080354181726442)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query\n",
    "write_query(\"I think mites have bitten me\")\n",
    "disease_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Common cold.txt', 0.62659839161061781),\n",
       " ('Cough.txt', 0.53201503192351374),\n",
       " ('Coughing up blood.txt', 0.44308745531623112),\n",
       " ('Cold intolerance.txt', 0.43211978373513765),\n",
       " ('Vitamin C and colds.txt', 0.29329506399237626)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query\n",
    "write_query(\"I have a cold and cough\")\n",
    "disease_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Paleness.txt', 0.53892340505888825),\n",
       " ('Fatigue.txt', 0.33874794670379049),\n",
       " ('Pupil - white spots.txt', 0.24364046824057434),\n",
       " ('Felty syndrome.txt', 0.15570268288106281),\n",
       " ('Skin care and incontinence.txt', 0.14670889378321389)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query\n",
    "write_query(\"I feel fatigued. My skin is pale and looks white\")\n",
    "disease_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hemolytic anemia.txt', 0.48362230206912082),\n",
       " ('Immune hemolytic anemia.txt', 0.47096286216783023),\n",
       " ('Drug-induced immune hemolytic anemia.txt', 0.44732235035296464),\n",
       " ('Hemolytic anemia caused by chemicals and toxins.txt', 0.40190572954635301),\n",
       " ('Anemia of chronic disease.txt', 0.37709923065132905)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query\n",
    "write_query(\"I have autoimmune hemolytic anemia\")\n",
    "disease_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cancer.txt', 0.66312498889843174),\n",
       " ('Lung cancer.txt', 0.47391585043495138),\n",
       " ('Colon cancer.txt', 0.43705885884448636),\n",
       " ('Vaginal cancer.txt', 0.43614152511923837),\n",
       " ('Breast cancer in men.txt', 0.43512193887205863)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test query\n",
    "write_query(\"I need to get treated for cancer\")\n",
    "disease_match()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
